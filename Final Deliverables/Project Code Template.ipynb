{
 "cells": [
  {
   "cell_type": "raw",
   "id": "33dd6c4c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Mushroom Classification: Project Code\"\n",
    "subtitle: Shake Shack\n",
    "author: Joseph Prette, Jackson Bremen, Lucy Han, and Chanel Sun \n",
    "date: 03/13/2023\n",
    "number-sections: true\n",
    "abstract: _This file contains the code for the project on mushroom edibility classification, as part of the STAT303-2 course in Winter 2023_.\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    self-contained: true\n",
    "    font-size: 100%\n",
    "    toc-depth: 4\n",
    "    mainfont: serif\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "## Data quality check / cleaning / preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db149d8b",
   "metadata": {},
   "source": [
    "### Data quality check and cleaning\n",
    "*By Joseph Prette*\n",
    "\n",
    "1. The following section briefly explores the basics of the data\n",
    "2. Removes row of missing values from end of dataframe\n",
    "3. Explores columns which feature a rare category that may be of high influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491403d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Import file\n",
    "train = pd.read_csv('./Data/expanded', delimiter='\\t', header=None, names=['characteristics'])\n",
    "train = train['characteristics'].str.split(',', expand=True)\n",
    "train = train.drop(range(7)).reset_index(drop=True)\n",
    "\n",
    "# Implement descriptive column names\n",
    "column_names = ['edibility','cap_shape', 'cap_surface', 'cap_color', 'bruises', \n",
    "                'odor', 'gill_attachment', 'gill_spacing', 'gill_size', 'gill_color', \n",
    "                'stalk_shape', 'stalk_root', 'stalk_surface_above_ring', 'stalk_surface_below_ring', \n",
    "                'stalk_color_above_ring', 'stalk_color_below_ring', 'veil_type', 'veil_color', \n",
    "                'ring_number', 'ring_type', 'spore_print_color', 'population','habitat']\n",
    "train.columns = column_names\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83436148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shape of data\n",
    "original_shape = train.shape\n",
    "print('The dataset has {} entries, with {} characteristics'.format(original_shape[0], original_shape[1]))\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of missing values in each column\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea58de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show rows with missing columns\n",
    "train[train.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a623dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows (in this case just the one row) containing any NA or None values\n",
    "train = train.drop(train[train.isnull().any(axis=1)].index)\n",
    "\n",
    "# show shape has changed:\n",
    "updated_shape = train.shape\n",
    "print('The dataset has {} entries, with {} characteristics'.format(updated_shape[0], updated_shape[1]))\n",
    "print('{} row(s) were removed'.format(original_shape[0] - updated_shape[0]))\n",
    "print('{} column(s) were removed'.format(original_shape[1] - updated_shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the updated description of the data\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rare is commonly defined as < .1%, using .1% as threshold for values.\n",
    "col_with_rare = list()\n",
    "for col_name in train.columns:\n",
    "    for n in range(len(train[col_name].value_counts())):\n",
    "        if train[col_name].value_counts()[n] / train.shape[0] < 0.001:\n",
    "            col_with_rare.append(col_name)\n",
    "            #print(train[col_name].value_counts())\n",
    "            #print()\n",
    "            break;\n",
    "\n",
    "col_with_rare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b2208",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "*By Jackson Bremen*\n",
    "\n",
    "1. Verified data is not severely imbalanced\n",
    "2. Implemented dummy variable for edibility\n",
    "3. Split given data into a training (80%) and test (20%) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb5aba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.edibility.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be94b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummy variables for two-level response\n",
    "def var_transform (data):\n",
    "    data['edibility']=data['edibility'].apply(lambda x: 1 if x=='EDIBLE' else 0)\n",
    "    # put further variable transformation here \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement transformation and verify change was successful\n",
    "var_transform(train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10732af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and test datasets\n",
    "np.random.seed(2)\n",
    "splitted_train = train.sample(round(train.shape[0]*0.8))\n",
    "test = train.drop(splitted_train.index)\n",
    "train = splitted_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1500222",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb11c9b",
   "metadata": {},
   "source": [
    "### Exploratory data analysis\n",
    "*By Chanel Sun and Jackson Bremen*\n",
    "\n",
    "1. Discovered `odor` to be very strong predictor for edibility, with certain odors having all or none edible, and just one with ~97% edible\n",
    "2. Decided to build model using only `odor`, but acknowledge the limitations and will build second without `odor`\n",
    "3. `veil-type` has only one level, 'PARTIAL', meaning it will have no effect on edibility, so this variable will not be used.\n",
    "4. We observed that the barplots of `stalk_surface_above_ring` and `stalk_surface_below_ring`, as well as `stalk_color_above_ring` and `stalk_color_below_ring`, showed a high degree of similarity. One from each will be dropped using SelectKBest.\n",
    "5. Use VIF to determine high influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4cf3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of the prediction variables; all but the first column (edibility)\n",
    "predictors = train.columns[1:]\n",
    "\n",
    "# Display the edibility of each cateogry of each prediction variable\n",
    "fig, axs = plt.subplots(6, 4, figsize=(20, 20))\n",
    "for i, predictor in enumerate(predictors):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    data = train[['edibility', predictor]].groupby([predictor], as_index=False).mean()\n",
    "    sns.barplot(x=predictor, y='edibility', data=data, ax=axs[row, col])\n",
    "    axs[row, col].set_title(f'{predictor}')\n",
    "    axs[row, col].set_xlabel('')\n",
    "    axs[row, col].set_ylabel('% edibility')\n",
    "    for rect in axs[row, col].patches:\n",
    "        height = rect.get_height()\n",
    "        axs[row, col].annotate(f'{height:.1%}', xy=(rect.get_x() + rect.get_width() / 2, height), \n",
    "                               xytext=(0, 3), textcoords='offset points', ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf4f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make temporary dataset without unnecessary columns, save response variable column as Y\n",
    "X = train.drop(['edibility', 'veil_type', 'stalk_surface_below_ring', 'stalk_color_below_ring'], axis=1)\n",
    "Y = train['edibility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20625e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement dummy variables for all columns since they are all categorical\n",
    "X = pd.get_dummies(X, columns=['cap_shape', 'cap_surface', 'cap_color', 'bruises', \n",
    "                'odor', 'gill_attachment', 'gill_spacing', 'gill_size', 'gill_color', \n",
    "                'stalk_shape', 'stalk_root', 'stalk_surface_above_ring',  \n",
    "                'stalk_color_above_ring', 'veil_color', 'ring_number', 'ring_type', \n",
    "                'spore_print_color', 'population','habitat'], drop_first=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89310f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get variable inflation factors\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"Predictor\"] = X.columns\n",
    "vif_inf = vif[np.isinf(vif['VIF Factor'])]\n",
    "vif_inf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab331a",
   "metadata": {},
   "source": [
    "## Developing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa684a3e",
   "metadata": {},
   "source": [
    "### Model Constrution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ec4c9",
   "metadata": {},
   "source": [
    "#### Model 1: `odor`\n",
    "*By Chanel Sun and Lucy Han*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450feda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute confusion matrix and prediction accuracy\n",
    "def confusion_matrix_data(data,actual_values,model,cutoff=0.5):\n",
    "    pred_values = model.predict(data)\n",
    "    bins=np.array([0,cutoff,1])\n",
    "    cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n",
    "    cm_df = pd.DataFrame(cm)\n",
    "    cm_df.columns = ['Predicted 0','Predicted 1']\n",
    "    cm_df = cm_df.rename(index={0: 'Actual 0',1:'Actual 1'})\n",
    "# Calculate the accuracy\n",
    "    accuracy = (cm[0,0]+cm[1,1])/cm.sum()\n",
    "    fnr = (cm[1,0])/(cm[1,0]+cm[1,1])\n",
    "    precision = (cm[1,1])/(cm[0,1]+cm[1,1])\n",
    "    fpr = (cm[0,1])/(cm[0,0]+cm[0,1])\n",
    "    tpr = (cm[1,1])/(cm[1,0]+cm[1,1])\n",
    "    fpr_roc, tpr_roc, auc_thresholds = roc_curve(actual_values, pred_values)\n",
    "    auc_value = (auc(fpr_roc, tpr_roc))# AUC of ROC\n",
    "    sns.heatmap(cm_df, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.ylabel(\"Actual Values\")\n",
    "    plt.xlabel(\"Predicted Values\")\n",
    "    print(\"Classification accuracy = {:.1%}\".format(accuracy))\n",
    "    print(\"Precision = {:.1%}\".format(precision))\n",
    "    print(\"TPR or Recall = {:.1%}\".format(tpr))\n",
    "    print(\"FNR = {:.1%}\".format(fnr))\n",
    "    print(\"FPR = {:.1%}\".format(fpr))\n",
    "    print(\"ROC-AUC = {:.1%}\".format(auc_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eedbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train.copy()\n",
    "\n",
    "# If odor is equal to ALMOND, ANISE, or NONE, set it to 0, else 1\n",
    "train_1['odor'] = train_1['odor'].apply(lambda x: 0 if x in ['ALMOND', 'ANISE', 'NONE'] else 1).astype(int)\n",
    "\n",
    "# Train a linear regression model\n",
    "model_1 = smf.logit(formula = 'edibility ~ odor', data=train_1).fit()\n",
    "\n",
    "confusion_matrix_data(test_1[['odor']], test_1['edibility'], model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9e4a70",
   "metadata": {},
   "source": [
    "#### Model 2: Complex Model\n",
    "*By Chanel Sun and Lucy Han*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91751cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = train.copy()\n",
    "\n",
    "train_2['edibility'] = train_2['edibility'].astype(int)\n",
    "\n",
    "columns_to_use = ['cap_shape', 'cap_surface', 'cap_color', 'bruises',\n",
    "                  'gill_attachment', 'gill_spacing', 'gill_size', 'stalk_color_above_ring']\n",
    "\n",
    "formula = 'edibility ~ ' + ' + '.join(columns_to_use)\n",
    "\n",
    "# Train a linear regression model\n",
    "model_2 = smf.logit(formula = formula, data = train_2).fit()\n",
    "\n",
    "# Test the model on the test set\n",
    "test_2 = test.copy()\n",
    "test_2['edibility'] = test_2['edibility'].astype(int)\n",
    "\n",
    "confusion_matrix_data(test_2[columns_to_use], test_2['edibility'], model_2, cutoff=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71084744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_vs_threshold(precision, recall, thresholds):\n",
    "    plt.plot(thresholds, precision[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recall[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.ylabel(\"Precision/Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7fa154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the optimal cutoff\n",
    "y = train_2['edibility']\n",
    "y_predict = model_2.predict(train_2)\n",
    "p, r, prc_thresholds = precision_recall_curve(train_2['edibility'], model_2.predict(train_2))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y, y_predict)\n",
    "\n",
    "plot_precision_vs_threshold(p, r, prc_thresholds)\n",
    "\n",
    "maximizing_threshold = thresholds[np.argmax(p[:-1] * r[:-1])]\n",
    "\n",
    "print(f\"When the threshold is {round(maximizing_threshold, 5)}\")\n",
    "print(f\"the precision is {round(p[np.argmin(np.abs(thresholds - maximizing_threshold))], 5)}\")\n",
    "print(f\"the recall is {round(r[np.argmin(np.abs(thresholds - maximizing_threshold))], 5)}\")\n",
    "print(f\"maximizing_threshold is {round(maximizing_threshold, 5)}\")\n",
    "\n",
    "# Find the point in precision where threshold is closest to maximizing_threshold\n",
    "\n",
    "y0 = p[np.argmin(np.abs(thresholds - maximizing_threshold))]\n",
    "y1 = r[np.argmin(np.abs(thresholds - maximizing_threshold))]\n",
    "\n",
    "sns.scatterplot(x=[maximizing_threshold], y=[y0], color='red', s=100)\n",
    "sns.scatterplot(x=[maximizing_threshold], y=[y1], color='red', s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6444e611",
   "metadata": {},
   "source": [
    "### Code fitting the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b277049",
   "metadata": {},
   "source": [
    "#### Model 1: `odor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22edc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = smf.logit(formula = 'edibility ~ odor', data=train_1).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f58ee0",
   "metadata": {},
   "source": [
    "#### Model 2: Complex Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefdcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = ['cap_shape', 'cap_surface', 'cap_color', 'bruises',\n",
    "                  'gill_attachment', 'gill_spacing', 'gill_size', 'stalk_color_above_ring']\n",
    "\n",
    "formula = 'edibility ~ cap_shape + cap_surface + cap_color + bruises + gill_attachment + gill_spacing + gill_size + stalk_color_above_ring'\n",
    "\n",
    "model_2 = smf.logit(formula = formula, data = train_2).fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
